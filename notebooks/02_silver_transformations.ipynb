{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da409af4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f09a3fa2",
   "metadata": {},
   "source": [
    "jupyter:\n",
    "  jupytext:\n",
    "    formats: ipynb,py:light\n",
    "    text_representation:\n",
    "      extension: .py\n",
    "      format_name: light\n",
    "      format_version: '1.5'\n",
    "      jupytext_version: 1.18.1\n",
    "  kernelspec:\n",
    "    display_name: Python 3 (ipykernel)\n",
    "    language: python\n",
    "    name: python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eab09a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e33a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"__file__\" in globals():\n",
    "    # Running from a script (e.g., src/01_bronze_ingestion.py)\n",
    "    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n",
    "else:\n",
    "    # Running from a notebook inside /notebooks\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed96916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.spark_config import create_spark\n",
    "from pyspark.sql import functions as F, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e16196d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bronze_path = os.path.join(project_root, \"delta\", \"bronze\") + \"/\"\n",
    "silver_path = os.path.join(project_root, \"delta\", \"silver\") + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b3c20cb5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def read_bronze_tables(spark):\n",
    "    \"\"\"Load all Bronze Delta tables into a dictionary.\"\"\"\n",
    "    return {\n",
    "        \"orders\": spark.read.format(\"delta\").load(f\"{bronze_path}olist_orders_dataset\"),\n",
    "        \"order_items\": spark.read.format(\"delta\").load(f\"{bronze_path}olist_order_items_dataset\"),\n",
    "        \"payments\": spark.read.format(\"delta\").load(f\"{bronze_path}olist_order_payments_dataset\"),\n",
    "        \"customers\": spark.read.format(\"delta\").load(f\"{bronze_path}olist_customers_dataset\"),\n",
    "        \"products\": spark.read.format(\"delta\").load(f\"{bronze_path}olist_products_dataset\"),\n",
    "        \"sellers\": spark.read.format(\"delta\").load(f\"{bronze_path}olist_sellers_dataset\"),\n",
    "        \"reviews\": spark.read.format(\"delta\").load(f\"{bronze_path}olist_order_reviews_dataset\"),\n",
    "        \"translations\": spark.read.format(\"delta\").load(f\"{bronze_path}product_category_name_translation\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ace3a7e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def clean_dataframe(df: DataFrame, subset_cols: list[str]) -> DataFrame:\n",
    "    \"\"\"Remove duplicates and null values based on subset columns.\"\"\"\n",
    "    return df.dropDuplicates().dropna(subset=subset_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "285964ff",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def add_derived_columns(orders: DataFrame, order_items: DataFrame, payments: DataFrame):\n",
    "    \"\"\"Add calculated columns for total price, profit margin, delivery time, and payment count.\"\"\"\n",
    "    order_items = (\n",
    "        order_items\n",
    "        .withColumn(\"total_price\", F.col(\"price\") + F.col(\"freight_value\"))\n",
    "        .withColumn(\"profit_margin\", F.col(\"price\") - F.col(\"freight_value\"))\n",
    "    )\n",
    "\n",
    "    orders = orders.withColumn(\n",
    "        \"delivery_time_days\",\n",
    "        F.datediff(F.col(\"order_delivered_customer_date\"), F.col(\"order_purchase_timestamp\"))\n",
    "    )\n",
    "\n",
    "    payments_agg = (\n",
    "        payments\n",
    "        .groupBy(\"order_id\")\n",
    "        .agg(F.sum(\"payment_installments\").alias(\"payment_count\"))\n",
    "    )\n",
    "\n",
    "    return orders, order_items, payments_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "84491c76",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_silver_tables(orders, customers, order_items, payments_agg, reviews, products, sellers, translations):\n",
    "    \"\"\"Join datasets to create enriched Silver tables.\"\"\"\n",
    "    silver_orders = (\n",
    "        orders\n",
    "        .join(customers, \"customer_id\", \"left\")\n",
    "        .join(payments_agg, \"order_id\", \"left\")\n",
    "        .join(reviews.select(\"order_id\", \"review_score\"), \"order_id\", \"left\")\n",
    "    )\n",
    "\n",
    "    silver_order_items = (\n",
    "        order_items\n",
    "        .join(products, \"product_id\", \"left\")\n",
    "        .join(sellers, \"seller_id\", \"left\")\n",
    "        .join(translations, \"product_category_name\", \"left\")\n",
    "    )\n",
    "\n",
    "    return silver_orders, silver_order_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "94e18311",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def write_delta(df: DataFrame, name: str):\n",
    "    \"\"\"Write DataFrame as a Delta table to the Silver path.\"\"\"\n",
    "    path = f\"{silver_path}{name}\"\n",
    "    df.write.format(\"delta\").mode(\"overwrite\").save(path)\n",
    "    print(f\" Written {name} to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18789b7a-af4a-48ac-9a82-139753cf3c2e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Pipeline entrypoint for Silver transformation.\"\"\"\n",
    "    spark = create_spark(\"Silver transformations\")\n",
    "    bronze = read_bronze_tables(spark)\n",
    "\n",
    "    orders = clean_dataframe(bronze[\"orders\"], [\"order_id\"])\n",
    "    order_items = clean_dataframe(bronze[\"order_items\"], [\"order_id\", \"price\"])\n",
    "    payments = clean_dataframe(bronze[\"payments\"], [\"order_id\"])\n",
    "    customers = clean_dataframe(bronze[\"customers\"], [\"customer_id\"])\n",
    "    reviews = clean_dataframe(bronze[\"reviews\"], [\"order_id\"])\n",
    "    products = clean_dataframe(bronze[\"products\"], [\"product_id\"])\n",
    "    sellers = clean_dataframe(bronze[\"sellers\"], [\"seller_id\"])\n",
    "    translations = clean_dataframe(bronze[\"translations\"], [\"product_category_name\"])\n",
    "\n",
    "    orders, order_items, payments_agg = add_derived_columns(orders, order_items, payments)\n",
    "\n",
    "    silver_orders, silver_order_items = create_silver_tables(\n",
    "        orders, customers, order_items, payments_agg, reviews, products, sellers, translations\n",
    "    )\n",
    "\n",
    "    write_delta(silver_orders, \"orders_enriched\")\n",
    "    write_delta(silver_order_items, \"order_items_enriched\")\n",
    "    orders = spark.read.format(\"delta\").load(\"../delta/silver/orders_enriched\")\n",
    "    order_items = spark.read.format(\"delta\").load(\"../delta/silver/order_items_enriched\")\n",
    "\n",
    "    common_orders = orders.join(order_items, \"order_id\", \"inner\")\n",
    "    print(\"Matched orders count:\", common_orders.count())\n",
    "\n",
    "    orders_count = orders.count()\n",
    "    items_count = order_items.count()\n",
    "    print(f\"Orders: {orders_count}, Items: {items_count}, Matched: {common_orders.count()}\")\n",
    "\n",
    "\n",
    "    spark.stop()\n",
    "    print(\"Silver transformation completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4676ae63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Written orders_enriched to /home/arber/lufthansa-data-project/delta/silver/orders_enriched\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Written order_items_enriched to /home/arber/lufthansa-data-project/delta/silver/order_items_enriched\n",
      "Matched orders count: 113314\n",
      "Orders: 99992, Items: 112650, Matched: 113314\n",
      "Silver transformation completed successfully.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
